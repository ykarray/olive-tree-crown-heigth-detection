{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G9jfJ9ooew-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxtq_kU-tedR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.utils.data as data\n",
        "import torchvision.models as models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX2LDXZctg1y"
      },
      "outputs": [],
      "source": [
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ7Ia-xWuQ7U"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "# root_dir = '../input/output-crns/CRNS_OUTPUT'\n",
        "class HeightandWidth(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)  # Chargement des données à partir d'un fichier CSV\n",
        "        self.root_dir = root_dir  # Répertoire racine contenant les images\n",
        "        self.transform = transform  # Transformation à appliquer aux images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)  # Retourne la taille du dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])  # Chemin d'accès à l'image\n",
        "        print(img_name)\n",
        "        image = cv2.imread(img_name)  # Lecture de l'image à l'aide de OpenCV\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Conversion de l'espace de couleur de BGR à RGB\n",
        "\n",
        "        label = self.data.iloc[idx, 1]  # Extraction de l'étiquette associée à l'image\n",
        "\n",
        "        if self.transform:\n",
        "            pic = self.transform(image)  # Application de la transformation spécifiée aux images\n",
        "\n",
        "        return pic, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R96w3rhVuTD4"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),  # Convertir l'image en objet de type PIL (Pillow)\n",
        "    transforms.Resize((900, 700)),\n",
        "    transforms.RandomRotation(10),  # Effectuer une rotation aléatoire de l'image dans la plage de -10 à +10 degrés\n",
        "    transforms.ToTensor()  # Convertir l'image en tenseur PyTorch\n",
        "])\n",
        "#transforms.Resize((900, 700)),  # Redimensionner l'image à une taille spécifiée"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IKp1Zj-uVgZ"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    real_values = []  # To store real values\n",
        "    predicted_values = []\n",
        "    for inputs, labels in train_loader:\n",
        "        #print(\"\\n labels\",labels)\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels.unsqueeze_(dim=1)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        #print(\"label float(train)\",labels.float(),\"outputs\",outputs)\n",
        "        loss = loss_fn(outputs, labels.float())\n",
        "        real_values.extend(labels.float().tolist())\n",
        "        predicted_values.extend(outputs.tolist())\n",
        "        losses.append(loss.item())\n",
        "       # Calcul des gradients, mise à jour des poids et réinitialisation des gradients à zéro\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    threshold = 0.25\n",
        "    matches = (np.array(predicted_values) >= (np.array(real_values) - threshold)) & (np.array(predicted_values) <= (np.array(real_values) + threshold))\n",
        "    matches_tensor = torch.from_numpy(matches.astype(int))\n",
        "    correct_predictions += torch.sum(matches_tensor)\n",
        "        # Calcul des gradients, mise à jour des poids et réinitialisation des gradients à zéro\n",
        "\n",
        "    plt.scatter(real_values, predicted_values)\n",
        "    plt.xlabel('Real Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.title('Real Values vs Predicted Values(train)')\n",
        "    plt.show()\n",
        "    # Mise à jour du scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Calcul de la précision et de la perte moyenne\n",
        "    return float(correct_predictions) / len(predicted_values), np.mean(losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFneawQuuZNq"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, validation_loader, loss_fn, device, n_examples):\n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    real_values = []  # To store real values\n",
        "    predicted_values = []\n",
        "\n",
        "    for inputs, labels in validation_loader:\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        #print(\"inputs :\",inputs)\n",
        "        labels = labels.to(device)\n",
        "        labels.unsqueeze_(dim=1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        #print('label_float(eval)',labels.float(),'  outputs  ',outputs)\n",
        "        # Calcul des prédictions et de la perte\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = loss_fn(outputs, labels.float())\n",
        "        real_values.extend(labels.float().tolist())\n",
        "        predicted_values.extend(outputs.tolist())\n",
        "        losses.append(loss.item())\n",
        "        # Mise à jour des prédictions correctes et des pertes\n",
        "    threshold = 0.25\n",
        "    matches = (np.array(predicted_values) >= (np.array(real_values) - threshold)) & (np.array(predicted_values) <= (np.array(real_values) + threshold))\n",
        "    matches_tensor = torch.from_numpy(matches.astype(int))\n",
        "    correct_predictions += torch.sum(matches_tensor)\n",
        "    plt.scatter(real_values, predicted_values)\n",
        "\n",
        "    plt.xlabel('Real Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.title('Real Values vs Predicted Values(val)')\n",
        "    plt.show()\n",
        "    # Calcul de la précision et de la perte moyenne\n",
        "    return float(correct_predictions) / len(predicted_values), np.mean(losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC-qpr6_ub-W"
      },
      "outputs": [],
      "source": [
        "def train_model(model, device, n_epochs=60):\n",
        "    dataset = HeightandWidth(csv_file='/content/drive/MyDrive/olive/Tree_height.csv',\n",
        "                          root_dir='/content/drive/MyDrive/olive/segmented/',\n",
        "                          transform=transform)\n",
        "\n",
        "    batch_size = 5\n",
        "    validation_split = 0.2\n",
        "    shuffle_dataset = True\n",
        "    random_seed = 42\n",
        "\n",
        "    # Obtention de la taille du jeu de données\n",
        "    dataset_size = len(dataset)\n",
        "    print(\"\\n dataset_size\",dataset_size)\n",
        "    # Création de la liste des indices des échantillons\n",
        "    indices = list(range(dataset_size))\n",
        "    print(\"\\n indices\",indices)\n",
        "    # Calcul de l'indice de séparation entre les ensembles d'entraînement et de validation\n",
        "    split = int(np.floor(validation_split * dataset_size))\n",
        "    print(\"\\n split\",split)\n",
        "\n",
        "    # Mélange aléatoire des indices si shuffle_dataset est True\n",
        "    if shuffle_dataset:\n",
        "      np.random.seed(random_seed)\n",
        "      np.random.shuffle(indices)\n",
        "\n",
        "    # Division des indices en ensembles d'entraînement et de validation\n",
        "    train_indices, val_indices = indices[split:], indices[:split]\n",
        "    print(\"\\n train_indices\",train_indices)\n",
        "    print(\"\\n val_indices\",val_indices)\n",
        "\n",
        "    # Création des échantillonneurs pour les ensembles d'entraînement et de validation\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = SubsetRandomSampler(val_indices)\n",
        "    print(\"\\n train_sampler\",train_sampler)\n",
        "    print(\"\\n valid_sampler\",valid_sampler)\n",
        "\n",
        "    # Création des chargeurs de données pour l'entraînement et la validation\n",
        "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "    # Set requires_grad=False for all parameters initially\n",
        "    save_dir = '/content/drive/MyDrive/olive/'\n",
        "    #weight_decay = 0.001\n",
        "    weight_decay = 0\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.6,weight_decay=weight_decay)\n",
        "    scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    history = defaultdict(list)\n",
        "    best_accuracy = 0\n",
        "    best_train_loss=0\n",
        "    best_test_loss=0\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{n_epochs}')\n",
        "        print('-' * 10)\n",
        "        #print(\"train loader\" ,len(train_loader))\n",
        "\n",
        "        # Entraînement du modèle\n",
        "        train_acc, train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device, scheduler, len(train_loader))\n",
        "        print(f'Train loss {train_loss}')\n",
        "        print(f'train acc {train_acc}')\n",
        "        # Évaluation du modèle sur les données de validation\n",
        "        val_acc, val_loss = eval_model(model, validation_loader, loss_fn, device, len(validation_loader))\n",
        "        print(f'Val loss {val_loss}')\n",
        "        print(f'val acc {val_acc}')\n",
        "        #print()\n",
        "        torch.save(model.state_dict(), save_dir + 'resnet50_18_07_checkpointx.pth')\n",
        "        # Enregistrement des métriques d'entraînement et de validation dans l'historique\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "\n",
        "        # Sauvegarde du meilleur modèle basé sur la précision de validation\n",
        "        if val_acc > best_accuracy:\n",
        "            torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "            best_accuracy = val_acc\n",
        "            best_train_loss=train_loss\n",
        "            best_test_loss = val_loss\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    plt.plot(epochs, history['train_loss'], 'b', label='Training Loss')\n",
        "    plt.plot(epochs, history['val_loss'], 'r', label='Validation Loss')\n",
        "    plt.title('Training Loss vs. Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.plot(epochs, history['train_acc'], 'b', label='Training Accuracy')\n",
        "    plt.plot(epochs, history['val_acc'], 'r', label='Validation Accuracy')\n",
        "    plt.title('Training Accuracy vs. Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print( \"best_accuracy: \", best_accuracy)\n",
        "    print(\"best_train_loss: \",best_train_loss)\n",
        "    print(\"best_test_loss: \",best_test_loss)\n",
        "\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNOBuBkHuhf1"
      },
      "outputs": [],
      "source": [
        "model50 = models.resnet50(pretrained=True)\n",
        "print(model50.fc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkt_CziyuoYn"
      },
      "outputs": [],
      "source": [
        "num_features = model50.fc.in_features\n",
        "\n",
        "print(\"Number of features:\", num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4DQ6jjout6f"
      },
      "outputs": [],
      "source": [
        "\n",
        "for param in model50.parameters():\n",
        "    # entrainer que final layer\n",
        "    param.required_grad = False\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model50.to(device)\n",
        "dropout_prob = 0  # Set the dropout probability\n",
        "\n",
        "model50.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 1024),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(dropout_prob),  # Add dropout layer here\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(dropout_prob),  # Add dropout layer here\n",
        "    nn.Linear(512, 128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(dropout_prob),  # Add dropout layer here\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(dropout_prob),  # Add dropout layer here\n",
        "    nn.Linear(64, 128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(dropout_prob),  # Add dropout layer here\n",
        "    nn.Linear(128, 1)\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koCa9R28vOkT"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "# Print the summary of the model\n",
        "summary(model50,input_size=(3,900, 700))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNOPsB26vTD4"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model50, history50 = train_model(model50, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5oEKRaevfy3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}